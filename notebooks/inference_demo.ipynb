{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c186c784",
   "metadata": {},
   "source": [
    "# **Détection de Langue: Démo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "922da3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sentencepiece as spm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba62fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26abbd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import BiLSTMSubword\n",
    "from src.predict import encode_text_sp, predict_language\n",
    "import src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bdb69b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.model' from '/workspaces/language-detection-nlp/src/model.py'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import src\n",
    "\n",
    "importlib.reload(src)\n",
    "importlib.reload(src.predict)\n",
    "importlib.reload(src.preprocess)\n",
    "# importlib.reload(src.data_loader)\n",
    "importlib.reload(src.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e12b2e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "CKPT: /workspaces/language-detection-nlp/models/bilstm_subword_final.pt\n",
      "SPM : /workspaces/language-detection-nlp/notebooks/spm_lang_detector.model\n",
      "LBL : /workspaces/language-detection-nlp/models/labels.json\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "CKPT_PATH = PROJECT_ROOT / \"models\" / \"bilstm_subword_final.pt\"\n",
    "SPM_PATH  = PROJECT_ROOT / \"notebooks\" / \"spm_lang_detector.model\"\n",
    "LABELS_PATH = PROJECT_ROOT / \"models\" / \"labels.json\"\n",
    "\n",
    "print(\"Device:\", DEVICE)\n",
    "print(\"CKPT:\", CKPT_PATH)\n",
    "print(\"SPM :\", SPM_PATH)\n",
    "print(\"LBL :\", LABELS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d02f429b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de labels: 17\n",
      "Aperçu: ['Arabic', 'Danish', 'Dutch', 'English', 'French']\n"
     ]
    }
   ],
   "source": [
    "# Chargeons les labels 'langue' - 'id'\n",
    "with open(LABELS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "id2label = {i: labels[i] for i in range(len(labels))}\n",
    "\n",
    "print(\"Nombre de labels:\", len(labels))\n",
    "print(\"Aperçu:\", labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c70dc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentencePiece vocab_size: 8000\n"
     ]
    }
   ],
   "source": [
    "# Chargeons SentencePiece\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(str(SPM_PATH))\n",
    "\n",
    "print(\"SentencePiece vocab_size:\", sp.get_piece_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1efc044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 17\n",
      "params: 17818641\n"
     ]
    }
   ],
   "source": [
    "# Charger le `checkpoint` et reconstruire le modèle\n",
    "\n",
    "checkpoint = torch.load(CKPT_PATH, map_location=DEVICE, weights_only=False)\n",
    "\n",
    "model = BiLSTMSubword(\n",
    "    vocab_size=checkpoint[\"vocab_size\"],\n",
    "    embedding_dim=checkpoint[\"embedding_dim\"],\n",
    "    hidden_dim=checkpoint[\"hidden_dim\"],\n",
    "    num_classes=checkpoint[\"num_classes\"],\n",
    "    n_layers=checkpoint[\"n_layers\"],\n",
    "    dropout=checkpoint[\"dropout\"],\n",
    ")\n",
    "\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "print(\"num_classes:\", checkpoint[\"num_classes\"])\n",
    "print(\"params:\", sum(p.numel() for p in model.parameters()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28301366",
   "metadata": {},
   "source": [
    "# **Démo rapide**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b310b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEXT: Ce projet de recherche vise à développer un système automatique capable de détecter la langue d’un texte donné avec une grande précision. L’objectif est d’analyser différentes approches d’apprentissage profond afin d’identifier la méthode la plus robuste face à des textes variés, qu’ils soient courts, longs, techniques ou conversationnels. L’évaluation du modèle repose sur plusieurs métriques telles que l’accuracy, le rappel et le score F1, tout en observant attentivement les erreurs entre langues proches partageant des caractéristiques lexicales similaires. Cette analyse approfondie permet d’améliorer progressivement les performances du système.\n",
      "TOP-3: [('French', 0.5606784224510193), ('Portugeese', 0.41460126638412476), ('Spanish', 0.011799817904829979)]\n",
      "\n",
      "TEXT: This research initiative focuses on designing an advanced language detection system using deep learning techniques. The goal is to create a model capable of identifying the language of an input text with high reliability, even when the sentences come from different domains or writing styles. The evaluation process includes analyzing confusion patterns between similar languages and studying how subword tokenization improves discrimination. By testing the model on external corpora, we aim to ensure that it generalizes effectively beyond the original training dataset.\n",
      "TOP-3: [('English', 0.9916662573814392), ('German', 0.004408334381878376), ('French', 0.001403224654495716)]\n",
      "\n",
      "TEXT: Este proyecto tiene como finalidad desarrollar un sistema inteligente capaz de identificar automáticamente el idioma de un texto determinado. Para lograrlo, se entrenan modelos de aprendizaje automático con datos multilingües y se evalúan sus resultados mediante métricas detalladas. La capacidad de generalización del modelo se analiza utilizando textos externos, lo que permite observar posibles confusiones entre idiomas que comparten estructuras gramaticales similares. Este enfoque garantiza una evaluación más realista del rendimiento del sistema.\n",
      "TOP-3: [('Portugeese', 0.960722029209137), ('Spanish', 0.034822333604097366), ('Turkish', 0.0014136594254523516)]\n",
      "\n",
      "TEXT: Dieses Projekt beschäftigt sich mit der Entwicklung eines Systems zur automatischen Spracherkennung auf der Grundlage moderner Methoden des maschinellen Lernens. Das Modell wird mit einem umfangreichen mehrsprachigen Datensatz trainiert und anschließend auf unabhängigen Texten getestet, um seine Generalisierungsfähigkeit zu überprüfen. Besonders wichtig ist die Analyse von Fehlern zwischen Sprachen mit ähnlicher Struktur, da diese häufig verwechselt werden. Durch eine sorgfältige Auswertung der Ergebnisse kann die Leistung des Systems kontinuierlich verbessert werden.\n",
      "TOP-3: [('German', 0.9877732396125793), ('Danish', 0.004145306535065174), ('Sweedish', 0.0040864781476557255)]\n",
      "\n",
      "TEXT: يهدف هذا المشروع البحثي إلى تطوير نظام ذكي قادر على التعرف التلقائي على لغة النصوص المكتوبة بدقة عالية. يتم تدريب النموذج باستخدام بيانات متعددة اللغات ثم يتم تقييم أدائه على نصوص جديدة للتأكد من قدرته على التعميم خارج مجموعة التدريب الأصلية. كما يتم تحليل الأخطاء التي تحدث بين اللغات المتشابهة في البنية أو المفردات، مما يساعد على تحسين النموذج وجعله أكثر استقرارًا في البيئات الواقعية.\n",
      "TOP-3: [('Arabic', 0.9999091625213623), ('Tamil', 2.5051756892935373e-05), ('Greek', 1.9365144908078946e-05)]\n"
     ]
    }
   ],
   "source": [
    "tests =  [\n",
    "\n",
    "\"Ce projet de recherche vise à développer un système automatique capable de détecter la langue d’un texte donné avec une grande précision. L’objectif est d’analyser différentes approches d’apprentissage profond afin d’identifier la méthode la plus robuste face à des textes variés, qu’ils soient courts, longs, techniques ou conversationnels. L’évaluation du modèle repose sur plusieurs métriques telles que l’accuracy, le rappel et le score F1, tout en observant attentivement les erreurs entre langues proches partageant des caractéristiques lexicales similaires. Cette analyse approfondie permet d’améliorer progressivement les performances du système.\", \n",
    "\n",
    "\"This research initiative focuses on designing an advanced language detection system using deep learning techniques. The goal is to create a model capable of identifying the language of an input text with high reliability, even when the sentences come from different domains or writing styles. The evaluation process includes analyzing confusion patterns between similar languages and studying how subword tokenization improves discrimination. By testing the model on external corpora, we aim to ensure that it generalizes effectively beyond the original training dataset.\", \n",
    "\n",
    "\"Este proyecto tiene como finalidad desarrollar un sistema inteligente capaz de identificar automáticamente el idioma de un texto determinado. Para lograrlo, se entrenan modelos de aprendizaje automático con datos multilingües y se evalúan sus resultados mediante métricas detalladas. La capacidad de generalización del modelo se analiza utilizando textos externos, lo que permite observar posibles confusiones entre idiomas que comparten estructuras gramaticales similares. Este enfoque garantiza una evaluación más realista del rendimiento del sistema.\", \n",
    "\n",
    "\"Dieses Projekt beschäftigt sich mit der Entwicklung eines Systems zur automatischen Spracherkennung auf der Grundlage moderner Methoden des maschinellen Lernens. Das Modell wird mit einem umfangreichen mehrsprachigen Datensatz trainiert und anschließend auf unabhängigen Texten getestet, um seine Generalisierungsfähigkeit zu überprüfen. Besonders wichtig ist die Analyse von Fehlern zwischen Sprachen mit ähnlicher Struktur, da diese häufig verwechselt werden. Durch eine sorgfältige Auswertung der Ergebnisse kann die Leistung des Systems kontinuierlich verbessert werden.\", \n",
    "\n",
    "\"يهدف هذا المشروع البحثي إلى تطوير نظام ذكي قادر على التعرف التلقائي على لغة النصوص المكتوبة بدقة عالية. يتم تدريب النموذج باستخدام بيانات متعددة اللغات ثم يتم تقييم أدائه على نصوص جديدة للتأكد من قدرته على التعميم خارج مجموعة التدريب الأصلية. كما يتم تحليل الأخطاء التي تحدث بين اللغات المتشابهة في البنية أو المفردات، مما يساعد على تحسين النموذج وجعله أكثر استقرارًا في البيئات الواقعية.\" \n",
    "]\n",
    "\n",
    "for t in tests:\n",
    "    res = predict_language(t, model, sp, id2label, DEVICE, top_k=3)\n",
    "    print(\"\\nTEXT:\", t)\n",
    "    print(\"TOP-3:\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f0279",
   "metadata": {},
   "source": [
    "### **Vérifions que le pipeline d’inférence est identique au training (diagnostic rapide)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2847f3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'welcome everyone', 'n_tokens': 6, 'unk_count': 0, 'unk_ratio': 0.0, 'first_pieces': ['▁', 'wel', 'co', 'me', '▁every', 'one'], 'first_ids': [4, 2508, 226, 221, 3959, 1091]}\n",
      "{'text': 'nature in the broadest sense is the natural physical material world', 'n_tokens': 14, 'unk_count': 0, 'unk_ratio': 0.0, 'first_pieces': ['▁nature', '▁in', '▁the', '▁broad', 'est', '▁sens', 'e', '▁is', '▁the', '▁natural', '▁physic', 'al', '▁material', '▁world'], 'first_ids': [159, 17, 14, 5682, 855, 865, 6, 51, 14, 1121, 3840, 60, 2072, 1717]}\n"
     ]
    }
   ],
   "source": [
    "def debug_sp(text, sp):\n",
    "    pieces = sp.encode(text, out_type=str)\n",
    "    ids = sp.encode(text, out_type=int)\n",
    "    unk_id = 1  # <unk>\n",
    "    unk_count = sum(1 for i in ids if i == unk_id)\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"n_tokens\": len(ids),\n",
    "        \"unk_count\": unk_count,\n",
    "        \"unk_ratio\": unk_count / max(1, len(ids)),\n",
    "        \"first_pieces\": pieces[:30],\n",
    "        \"first_ids\": ids[:30],\n",
    "    }\n",
    "\n",
    "print(debug_sp(\"welcome everyone\", sp))\n",
    "print(debug_sp(\"nature in the broadest sense is the natural physical material world\", sp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd35ea5",
   "metadata": {},
   "source": [
    "<u>**Observations:**</u>\n",
    "Ce qui se passe réellement <br />\n",
    "Le modèle est :\n",
    "- Très performant sur le test Kaggle (≈ 95%). Mais mal calibré sur des phrases courtes, génériques et hors domaine Wikipédia\n",
    "“Welcome everyone” est :\n",
    "- Très court\n",
    "- Très neutre\n",
    "- Lexicalement proche de plusieurs langues latines\n",
    "- Peu informatif statistiquement\n",
    "- Le modèle choisit donc une langue latine fréquente (Italian ici).\n",
    "\n",
    "C’est un comportement normal en production pour un modèle entraîné sur textes longs.\n",
    "\n",
    "**Conclusion technique**\n",
    "Ce n’est pas un bug.<br />\n",
    "C’est un problème de :\n",
    "- Distribution shift (Wikipédia vs phrase libre)\n",
    "- Manque de contexte\n",
    "- Ambiguïté linguistique courte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7e56e3",
   "metadata": {},
   "source": [
    "\n",
    "**Conclusion complémentaire**\n",
    "\n",
    "La performance du modèle est directement corrélée à la quantité d’information contextuelle disponible.  \n",
    "Plus le texte est long et structuré, plus la prédiction est stable et fiable.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
